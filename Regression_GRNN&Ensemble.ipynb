{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hight and width of the images\n",
    "IMAGE_SIZE = 100\n",
    "\n",
    "# 3 channels, Red, Green and Blue\n",
    "CHANNELS = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read total image from folder\n",
    "def read_image():\n",
    "    images = []\n",
    "    labels = []\n",
    "    folder_path = '//Users//jun//Desktop//Dataset//br-coins//all//'\n",
    "    \n",
    "    for image_name in os.listdir(folder_path):\n",
    "        image_path = folder_path + image_name\n",
    "        image_label = int(image_name.split('_')[0])\n",
    "        image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "        images.append(image)\n",
    "        labels.append(image_label)\n",
    "            \n",
    "    return images, labels\n",
    "\n",
    "\n",
    "# Extract coins from image\n",
    "def extract_coins(img):\n",
    "    # Convert to b&w\n",
    "    cimg = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    # Find circles on the image\n",
    "    circles = cv2.HoughCircles(\n",
    "        cimg, cv2.HOUGH_GRADIENT, 2, 60, param1=300, param2=30, minRadius=30, maxRadius=50)\n",
    "    \n",
    "    # Convert to HSV colorspace\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    # Define color range for masking\n",
    "    lower = np.array([0, 0, 0])\n",
    "    upper = np.array([255, 255, 90])\n",
    "    # Apply the mask\n",
    "    mask = cv2.blur(cv2.inRange(hsv, lower, upper), (10, 10))\n",
    "    \n",
    "    frames = []\n",
    "    radiuses = []\n",
    "    # If circles were not found\n",
    "    if circles is None:\n",
    "        return None, None\n",
    "    \n",
    "    for circle in circles[0]:\n",
    "        center_x = int(circle[0])\n",
    "        center_y = int(circle[1])\n",
    "        \n",
    "        # If center of coin lays in masked coin range\n",
    "        if not mask[center_y, center_x]:\n",
    "            continue\n",
    "        \n",
    "        # Increase radius by C, circle detector tends to decrease radius\n",
    "        radius = circle[2] + 3\n",
    "        \n",
    "        radiuses.append(radius)\n",
    "        \n",
    "        # Coordinates of upper left corner of square\n",
    "        x = int(center_x - radius)\n",
    "        y = int(center_y - radius)\n",
    "        \n",
    "        # As radius was increased the coordinates, could go out of bounds\n",
    "        if y < 0:\n",
    "            y = 0\n",
    "        if x < 0:\n",
    "            x = 0\n",
    "                \n",
    "        frames.append(img[y: int(y + 2 * radius), x: int(x + 2 * radius)])\n",
    "\n",
    "    return np.array(frames), radiuses\n",
    "\n",
    "\n",
    "# Rejoint images to a new one\n",
    "def image_joint(image_list):\n",
    "    image_size = 376\n",
    "    size = 0\n",
    "    img_dict = {}\n",
    "    count = 0\n",
    "    \n",
    "    # Get the size of the biggest one, resize all images with it\n",
    "    for img in image_list:\n",
    "        img_dict[count] = img.shape[0] * img.shape[1]\n",
    "        count += 1\n",
    "        if img.shape[0] >= size:\n",
    "            size = img.shape[0]\n",
    "        if img.shape[1] >= size:\n",
    "            size = img.shape[1] \n",
    "    \n",
    "    img_dict = sorted(img_dict.items(), key=lambda item:item[1])\n",
    "    new_image_list = []\n",
    "    for key, item in img_dict:\n",
    "        img = image_list[key]\n",
    "        if img.shape[0] < size or img.shape[1] < size:\n",
    "            new_img=Image.new('RGB', (size, size), '#FAFAFA')\n",
    "            new_img.paste(Image.fromarray(img), box=(0, 0, img.shape[1], img.shape[0]))\n",
    "            new_image_list.append(np.array(new_img))\n",
    "        else:\n",
    "            new_image_list.append(img)\n",
    "            \n",
    "    # Joint all single images to new one with original size\n",
    "    new_img=Image.new('RGB', (image_size, image_size), '#FAFAFA')\n",
    "    \n",
    "    for i in range(len(new_image_list)):\n",
    "        img = new_image_list[i]\n",
    "        \n",
    "        if i == 0:\n",
    "            lt = rt = 0\n",
    "            lb = size\n",
    "            rb = size\n",
    "        else:\n",
    "            if lb + size <= image_size:\n",
    "                lt += size\n",
    "                lb += size \n",
    "            else:\n",
    "                lt = 0\n",
    "                rt += size\n",
    "                lb = size\n",
    "                rb += size\n",
    "                \n",
    "        new_img.paste(Image.fromarray(img), box=(lt, rt, lb, rb))\n",
    "            \n",
    "    return np.array(new_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read all images fron folder\n",
    "all_image, all_label = read_image()\n",
    "all_image = np.array(all_image)\n",
    "all_label = np.array(all_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "labels = []\n",
    "for i in range(len(all_image)):\n",
    "    image = all_image[i]\n",
    "    label = all_label[i]\n",
    "\n",
    "    # Extract coins from image and rejoint to a new image\n",
    "    prepared, _ = extract_coins(image)\n",
    "\n",
    "    if prepared is not None and len(prepared):\n",
    "        # merge extracted coins back to on image\n",
    "        image = image_joint(prepared)\n",
    "\n",
    "        image = cv2.resize(image, (IMAGE_SIZE, IMAGE_SIZE))\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        images.append(image)\n",
    "        labels.append(label)\n",
    "\n",
    "all_image_new = np.array(images)\n",
    "all_label_new = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('coins_all_image_new.npy', all_image_new)\n",
    "np.save('coins_all_label_new.npy', all_label_new)\n",
    "all_image_new.shape, all_label_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_image_new = np.load('coins_all_image_new.npy')\n",
    "all_label_new = np.load('coins_all_label_new.npy')\n",
    "all_image_new.shape, all_label_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting\n",
    "# X_train, X_test, Y_train, Y_test = train_test_split(all_image_new, all_label_new, test_size=0.2, random_state=None)\n",
    "X_train = np.array([])\n",
    "X_test = np.array([])\n",
    "Y_train = np.array([])\n",
    "Y_test = np.array([])\n",
    "for label in np.unique(all_label_new):        \n",
    "    index = np.argwhere(all_label_new == label)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(all_image_new[index[:,0]], all_label_new[index[:,0]], test_size=0.2, random_state=None)\n",
    "    if len(X_train) == 0:\n",
    "        X_train = x_train\n",
    "        X_test = x_test\n",
    "        Y_train = y_train\n",
    "        Y_test = y_test\n",
    "    else:\n",
    "        X_train = np.concatenate((X_train, x_train), axis=0)\n",
    "        X_test = np.concatenate((X_test, x_test), axis=0)\n",
    "        Y_train = np.concatenate((Y_train, y_train), axis=0)\n",
    "        Y_test = np.concatenate((Y_test, y_test), axis=0)\n",
    "\n",
    "# Show first 10 images\n",
    "print(Y_train[0:10])\n",
    "\n",
    "slice = 10\n",
    "plt.figure(figsize=(16, 16))\n",
    "for i in range(slice):\n",
    "    plt.subplot(1, slice, i+1)\n",
    "    plt.imshow(X_train[i], interpolation='nearest')\n",
    "    plt.axis('off')    \n",
    "    \n",
    "print(Y_test[0:10])\n",
    "\n",
    "slice = 10\n",
    "plt.figure(figsize=(16, 16))\n",
    "for i in range(slice):\n",
    "    plt.subplot(1, slice, i+1)\n",
    "    plt.imshow(X_test[i], interpolation='nearest')\n",
    "    plt.axis('off')    \n",
    "    \n",
    "print(X_train.shape, Y_train.shape, X_test.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization\n",
    "X_train = X_train.astype(np.float32, copy=False)\n",
    "X_test = X_test.astype(np.float32, copy=False)\n",
    "\n",
    "mean = X_train.mean(axis=(0, 1, 2))\n",
    "std = X_train.std(axis=(0, 1, 2))\n",
    "\n",
    "X_train -= mean\n",
    "X_train /= std\n",
    "X_test -= mean\n",
    "X_test /= std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('coins_X_train.npy', X_train)\n",
    "np.save('coins_Y_train.npy', Y_train)\n",
    "np.save('coins_X_test.npy', X_test)\n",
    "np.save('coins_Y_test.npy', Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load('coins_X_train.npy')\n",
    "Y_train = np.load('coins_Y_train.npy')\n",
    "X_test = np.load('coins_X_test.npy')\n",
    "Y_test = np.load('coins_Y_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten data\n",
    "X_flat_train = X_train.reshape(X_train.shape[0], IMAGE_SIZE*IMAGE_SIZE*CHANNELS)\n",
    "X_flat_test = X_test.reshape(X_test.shape[0], IMAGE_SIZE*IMAGE_SIZE*CHANNELS)\n",
    "X_flat_train.shape, X_flat_test.shape, Y_train.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import math\n",
    "\n",
    "components = []\n",
    "errors = []\n",
    "\n",
    "i = 1\n",
    "while i>0:\n",
    "    i = i - 0.05\n",
    "    pca = PCA(i, copy=False, whiten=True) \n",
    "    X_flat_train = pca.fit_transform(X_flat_train)\n",
    "    X_flat_test = pca.transform(X_flat_test)\n",
    "    \n",
    "    # Construct grnn\n",
    "    grnnet = algorithms.GRNN(std=0.5, verbose=True)\n",
    "    grnnet.train(X_flat_train, Y_train)\n",
    "    \n",
    "    Y_pred = grnnet.predict(X_flat_test)\n",
    "    error = estimators.rmsle(Y_pred, Y_test)\n",
    "    \n",
    "    if math.isnan(error):\n",
    "        error = 1\n",
    "    components.append(\"%.2f\" % i)\n",
    "    errors.append(\"%.3f\" % error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(components, errors, color=\"red\", linewidth=2)  \n",
    "plt.xlabel(\"PCA Components\")  \n",
    "plt.ylabel(\"RMSLE\")  \n",
    "plt.title(\"GRNN RMSLE\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(0.8, copy=False, whiten=True) \n",
    "X_flat_train = pca.fit_transform(X_flat_train)\n",
    "X_flat_test = pca.transform(X_flat_test)\n",
    "\n",
    "sum(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_flat_train.shape, X_flat_test.shape, Y_train.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_flat_train[:,0], X_flat_train[:,1], marker='x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_flat_test[:,0], X_flat_test[:,1], marker='x')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets, preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from neupy import algorithms, estimators, environment\n",
    "\n",
    "# Construct grnn\n",
    "grnnet = algorithms.GRNN(std=0.5, verbose=True)\n",
    "grnnet.train(X_flat_train, Y_train)\n",
    "\n",
    "Y_pred = grnnet.predict(X_flat_test)\n",
    "\n",
    "error = estimators.rmsle(Y_pred, Y_test)\n",
    "print(\"GRNN RMSLE = {:.3f}\\n\".format(error))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = np.mean(abs(np.array(Y_test) - np.array(Y_pred)))\n",
    "print(\"Mean prediction error for images: {0:.2f} cents\".format(error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "cnn_model = load_model('coins_reg_cnn.final.h5')\n",
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cnn = cnn_model.predict(X_train)\n",
    "X_test_cnn = cnn_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_grnn = grnnet.predict(X_flat_train)\n",
    "X_test_grnn = grnnet.predict(X_flat_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate the two train probability arrays to one as the input of ensemble\n",
    "X_train_ens = np.concatenate((X_train_cnn, X_train_grnn), axis=1)\n",
    "X_test_ens = np.concatenate((X_test_cnn, X_test_grnn), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.asarray(Y_train).reshape(len(Y_train)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_epoch_end(network):\n",
    "    pred = network.predict(X_test_ens) \n",
    "    Y_pred.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neupy.algorithms import GradientDescent\n",
    "from neupy import algorithms, layers, environment\n",
    "from sklearn import metrics\n",
    "\n",
    "Y_pred = []\n",
    "\n",
    "model_ens = algorithms.MinibatchGradientDescent(\n",
    "    [layers.Input(2), layers.Tanh(1), layers.Linear(1)],\n",
    "    error='mse',\n",
    "    step=0.25,\n",
    "    shuffle_data=True,\n",
    "    batch_size=16,\n",
    "    verbose=True,\n",
    "    epoch_end_signal=on_epoch_end,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ens.architecture()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ens.train(X_train_ens, Y_train, X_test_ens, Y_test, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = np.mean(abs(np.array(Y_test) - np.array(Y_pred)))\n",
    "print(\"Mean prediction error for ensemble model: {0:.2f} cents\".format(error))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
